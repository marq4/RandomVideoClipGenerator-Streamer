---
name: CICD

on: push

jobs:
  # _ Meta-code _

  # Auxiliary job that checks if any YAML file(s) changed.
  any-yaml-changed:
    runs-on: ubuntu-latest
    timeout-minutes: 3
    outputs:
      any_yaml_files_were_updated:
        ${{ steps.detect_yaml_diff.outputs.any_changed }}
    steps:
      # Fetch all history for version tagging:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - id: detect_yaml_diff
        uses: ./.github/actions/changed-files
        with:
          files: "**/*.{yml,yaml}"
      - run: |
          echo 'Did any YAML file(s) change in this commit: '
          echo ${{ steps.detect_yaml_diff.outputs.any_changed }}

  # Auxiliary job that checks if any Terraform file(s) changed.
  any-tf-changed:
    runs-on: ubuntu-latest
    timeout-minutes: 3
    outputs:
      any_tf_files_were_updated:
        ${{ steps.detect_tf_diff.outputs.any_changed }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - id: detect_tf_diff
        uses: ./.github/actions/changed-files
        with:
          files: "**/*.tf"
      - run: |
          echo 'Did any Terraform file(s) change in this commit: '
          echo ${{ steps.detect_tf_diff.outputs.any_changed }}

  # Lint YAML.
  yaml-style-quality:
    needs: any-yaml-changed
    if: needs.any-yaml-changed.outputs.any_yaml_files_were_updated == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - uses: actions/checkout@v4

      - name: Lint YAML files.
        uses: frenck/action-yamllint@v1

  # Format + Validate + Lint Terraform:
  tf-style-quality:
    needs: any-tf-changed
    if: needs.any-tf-changed.outputs.any_tf_files_were_updated == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 11
    defaults:
      run:
        working-directory: ./Terraform
    env:
      MY_TFLINT_URL: >-
        'https://raw.githubusercontent.com/terraform-linters/tflint/master/install_linux.sh'

    steps:
      - uses: actions/checkout@v4

      - id: load_config
        run: echo "region=$(yq '.region' config.yml)" >> $GITHUB_OUTPUT

      - name: Verify no sensitive file(s) committed.
        run: |
          if find . -name "*.tfstate*" -o -name "*.tfvars" \
          | grep -q .
          then
            echo '!!! Caution !!! '
            echo 'Found sensitive Terraform file in commit. '
            echo 'Aborting. '
            exit 1
          fi

      - uses: hashicorp/setup-terraform@v3
        with:
          # Upgrade local when this breaks:
          terraform_version: latest   # Independent of local.

      - name: Install TFlint.
        run: curl -s  ${{ env.MY_TFLINT_URL }} | bash

      - run: terraform fmt -check -recursive
        continue-on-error: false

      - run: terraform init -backend=false
        env:
          AWS_REGION: ${{ steps.load_config.outputs.region }}

      - run: terraform validate

      - run: tflint --init && tflint


  # _ Python _

  # Auxiliary job that checks if any Python file(s) changed.
  any-python-changed:
    needs: yaml-style-quality
    # Run even if upstream was skipped, but not if it failed:
    if: ${{ !failure() && !cancelled() }}
    runs-on: ubuntu-latest
    timeout-minutes: 3
    outputs:
      any_python_files_were_updated:
        ${{ steps.detect_python_diff.outputs.any_changed }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - id: detect_python_diff
        uses: ./.github/actions/changed-files
        with:
          files: '**/*.py'
      - run: |
          echo 'Did any Python file(s) change in this commit: '
          echo ${{ steps.detect_python_diff.outputs.any_changed }}

  # Python lint, type-checking, import order, dependency audit.
  # Only runs if any Python files changed.
  # TMP: SKIPPING!!!
  python-code-quality:
    needs: any-python-changed
    # Run even if ANY upstream was skipped (like yaml-lint),
    #   but not if it failed:
    if: >
      !failure() && !cancelled() &&
      needs.any-python-changed.outputs.any_python_files_were_updated == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 9
    env:
      PYTHONPATH: .

    steps:
      # These first 2 steps cannot be skipped:
      - uses: actions/checkout@v4

      - id: load_config
        run: |
          echo "skip=$(yq '.skip_pylint' config.yml)" >> $GITHUB_OUTPUT
          echo "version=$(yq '.py_version' config.yml)" >> $GITHUB_OUTPUT

      - uses: ./.github/actions/set-up-python
        if: steps.load_config.outputs.skip != 'true'
        with:
          project-version: ${{ steps.load_config.outputs.version }}

      - uses: ./.github/actions/install-dependencies
        if: steps.load_config.outputs.skip != 'true'

      - name: Lint Python code.
        if: steps.load_config.outputs.skip != 'true'
        run: pylint .

      - name: Type checking.
        if: steps.load_config.outputs.skip != 'true'
        run: mypy .

      - name: Import ordering.
        if: steps.load_config.outputs.skip != 'true'
        run: isort --check .

      - name: Dependency security audit.
        if: steps.load_config.outputs.skip != 'true'
        run: pyscan

  # Runs on Windows: unit + code coverage, integration.
  # Only for a potential release and if code quality cleared.
  # TMP: SKIPPING tests!!!
  python-code-testing:
    needs: python-code-quality
    # Without the first conditions
    #   this job gets skipped IF yaml-lint job gets skipped,
    #   as it depends on it indirectly up the chain,
    #   (so no Python code tests if YAML doesn't change).
    # Only test Python code if commit will trigger a Release:
    if: >-
      !failure() && !cancelled() &&
      (startsWith(github.event.head_commit.message, 'feat') ||
      startsWith(github.event.head_commit.message, 'fix'))
    runs-on: windows-latest
    timeout-minutes: 13
    env:
      PYTHONPATH: .

    steps:
      # These first 3 steps cannot be skipped:
      - uses: actions/checkout@v4

      # - run: choco install yq -y #TMP!!!

      - id: load_config
        shell: bash
        run: |
          echo "skip=$(yq '.skip_pytest' config.yml)" >> $GITHUB_OUTPUT
          echo "version=$(yq '.py_version' config.yml)" >> $GITHUB_OUTPUT
          TARGET=$(yq '.coverage' config.yml)
          echo "coverage_target=$TARGET" >> $GITHUB_OUTPUT
          echo "folder_core=$(yq '.core_folder' config.yml)" >> $GITHUB_OUTPUT

      - name: Install FFMpeg, VLC.
        if: steps.load_config.outputs.skip != 'true'
        run: |
          choco install ffmpeg -y
          choco install vlc -y

      - uses: ./.github/actions/set-up-python
        if: steps.load_config.outputs.skip != 'true'
        with:
          project-version: ${{ steps.load_config.outputs.version }}

      - uses: ./.github/actions/install-dependencies
        if: steps.load_config.outputs.skip != 'true'

      - name: Setup (create fake example videos).
        if: steps.load_config.outputs.skip != 'true'
        run: python tests/setup.py

      - name: Unit testing.
        if: steps.load_config.outputs.skip != 'true'
        run: pytest -vvv tests/unit_tests.py

      - name: Code coverage.
        if: steps.load_config.outputs.skip != 'true'
        run: >
          pytest --cov=${{ steps.load_config.outputs.folder_core }}
          --cov-fail-under=${{ steps.load_config.outputs.coverage_target }}
          tests/unit_tests.py

      - name: Integration testing.
        if: steps.load_config.outputs.skip != 'true'
        run: pytest -vvv tests/integration_tests.py

  # Conventional Commits Release (PSR: Python Semantic Release).
  # Only runs if special commit message.
  release:
    needs: python-code-testing
    if: >-
      !failure() && !cancelled() &&
      needs.python-code-testing.result == 'success' &&
      (startsWith(github.event.head_commit.message, 'feat') ||
      startsWith(github.event.head_commit.message, 'fix'))
    runs-on: ubuntu-latest
    timeout-minutes: 9
    env:
      PYTHONPATH: .
    # Allow commits, tags, pushes:
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4

      - id: load_config
        run: echo "version=$(yq '.py_version' config.yml)" >> $GITHUB_OUTPUT

      - uses: ./.github/actions/set-up-python
        with:
          project-version: ${{ steps.load_config.outputs.version }}

      - run: python -m pip install python-semantic-release

      - name: Configure Git.
        run: |
          git config user.name 'github-actions[bot]'
          git config user.email 'github-actions[bot]@users.noreply.github.com'

      # Bump version, commit, tag, publish GitHub Release:
      - name: Semantic Release.
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        # Locally do: python -m semantic_release
        run: |
          semantic-release --strict --config pyproject.toml \
            version --skip-build --vcs-release

  deploy-to-s3-and-lambda:
    needs: release
    if: >-
      !failure() && !cancelled() &&
      needs.release.result == 'success'
    runs-on: ubuntu-latest
    timeout-minutes: 16
    env:
      PYTHONPATH: .

    steps:
      - name: Checkout code (deep, main).
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: main

      - name: Pull release.
        run: git pull origin main

      - id: load_config
        run: |
          echo "version=$(yq '.py_version' config.yml)" >> $GITHUB_OUTPUT
          echo "region=$(yq '.region' config.yml)" >> $GITHUB_OUTPUT
          echo "path_core=$(yq '.core_path' config.yml)" >> $GITHUB_OUTPUT
          echo "bucket_scripts=$(yq '.scripts_bucket' config.yml)" >> $GITHUB_OUTPUT
          echo "name_core=$(yq '.core_py' config.yml)" >> $GITHUB_OUTPUT
          echo "path_verify=$(yq '.verify' config.yml)" >> $GITHUB_OUTPUT
          echo "deploy_dir_core=$(yq '.core_zip_dir' config.yml)" >> $GITHUB_OUTPUT
          echo "zipfile_core=$(yq '.core_zipfile' config.yml)" >> $GITHUB_OUTPUT
          echo "lambda_core=$(yq '.core_function' config.yml)" >> $GITHUB_OUTPUT
          echo "zipfile_list=$(yq '.list_zipfile' config.yml)" >> $GITHUB_OUTPUT
          echo "path_list=$(yq '.list_src' config.yml)" >> $GITHUB_OUTPUT
          echo "lambda_list=$(yq '.list_function' config.yml)" >> $GITHUB_OUTPUT
          echo "deploy_dir_cleanup=$(yq '.cleanup_zip_dir' config.yml)" >> $GITHUB_OUTPUT
          echo "zipfile_cleanup=$(yq '.cleanup_zipfile' config.yml)" >> $GITHUB_OUTPUT
          echo "path_cleanup=$(yq '.cleanup_src' config.yml)" >> $GITHUB_OUTPUT
          echo "lambda_cleanup=$(yq '.cleanup_function' config.yml)" >> $GITHUB_OUTPUT
          echo "deploy_dir_upload=$(yq '.upload_zip_dir' config.yml)" >> $GITHUB_OUTPUT
          echo "zipfile_upload=$(yq '.upload_zipfile' config.yml)" >> $GITHUB_OUTPUT
          echo "path_upload=$(yq '.upload_src' config.yml)" >> $GITHUB_OUTPUT
          echo "lambda_upload=$(yq '.upload_function' config.yml)" >> $GITHUB_OUTPUT
          echo "folder_core=$(yq '.core_folder' config.yml)" >> $GITHUB_OUTPUT

      - uses: ./.github/actions/set-up-python
        with:
          project-version: ${{ steps.load_config.outputs.version }}

      # No need to install AWS CLI.
      # These are needed or import breaks.
      # (Script is executed to verify version).
      - run: python -m pip install boto3 boto3-stubs boto3-stubs[s3] PyYAML

      - name: Load AWS credentials from GitHub secrets.
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID_RVCGS }}
          aws-secret-access-key: >
            ${{ secrets.AWS_SECRET_ACCESS_KEY_RVCGS }}
          aws-region: ${{ steps.load_config.outputs.region }}

      - name: Upload core script to S3 and verify correct version is live.
        env:
          MY_CORE_PATH: ${{ steps.load_config.outputs.path_core }}
          MY_BUCKET: ${{ steps.load_config.outputs.bucket_scripts }}
          MY_CORE_NAME: ${{ steps.load_config.outputs.name_core }}
          MY_VERIFY_BASH: ${{ steps.load_config.outputs.path_verify }}
        run: |
          aws s3 cp \
          ${{ env.MY_CORE_PATH }} \
          s3://${{ env.MY_BUCKET }}/${{ env.MY_CORE_NAME }} \
          --content-type 'text/x-python' \
          --content-disposition "attachment; filename=${{ env.MY_CORE_NAME }}" \
          --metadata-directive REPLACE
          sleep 3
          chmod +x ${{ env.MY_VERIFY_BASH }}
          ${{ env.MY_VERIFY_BASH }} \
            "${{ steps.load_config.outputs.folder_core }}" \
            "${{ env.MY_CORE_NAME }}" \
            "${{ env.MY_BUCKET }}"

      - name: Deploy core code to Lambda (website / Cloud service users).
        env:
          MY_DIR: ${{ steps.load_config.outputs.deploy_dir_core }}
          MY_ZIPFILE: ${{ steps.load_config.outputs.zipfile_core }}
        run: |
          mkdir ${{ env.MY_DIR }}
          cd ${{ env.MY_DIR }}
          python -m pip install boto3 mypy-boto3-s3 PyYAML -t .
          cp "../${{ steps.load_config.outputs.path_core }}" .
          cp ../config.yml .
          zip --quiet -r "../${{ env.MY_ZIPFILE }}" . \
          -x "*.pyc" -x "*__pycache__*" -x "*.dist-info*"
          cd ..
          ls -ltAh | tail -n +2 | head -1
          aws lambda update-function-code \
          --function-name ${{ steps.load_config.outputs.lambda_core }} \
          --zip-file fileb://${{ env.MY_ZIPFILE }}

      - name: Deploy suggestions list code to Lambda.
        env:
          MY_ZIPFILE: ${{ steps.load_config.outputs.zipfile_list }}
        run: |
          zip --quiet --junk-paths ${{ env.MY_ZIPFILE }} \
          "${{ steps.load_config.outputs.path_list }}" List.md
          ls -ltAh | tail -n +2 | head -1
          aws lambda update-function-code \
          --function-name ${{ steps.load_config.outputs.lambda_list }} \
          --zip-file fileb://${{ env.MY_ZIPFILE }}

      - name: Deploy S3 cleanup code to Lambda.
        env:
          MY_DIR: ${{ steps.load_config.outputs.deploy_dir_cleanup }}
          MY_ZIPFILE: ${{ steps.load_config.outputs.zipfile_cleanup }}
        run: |
          mkdir ${{ env.MY_DIR }}
          cd ${{ env.MY_DIR }}
          python -m pip install boto3 -t .
          cp "../${{ steps.load_config.outputs.path_cleanup }}" .
          cp ../config.yml .
          zip --quiet -r "../${{ env.MY_ZIPFILE }}" . \
          -x "*.pyc" -x "*__pycache__*" -x "*.dist-info*"
          cd ..
          ls -ltAh | tail -n +2 | head -1
          aws lambda update-function-code \
          --function-name ${{ steps.load_config.outputs.lambda_cleanup }} \
          --zip-file fileb://${{ env.MY_ZIPFILE }}

      - name: Deploy upload code.
        env:
          MY_DIR: ${{ steps.load_config.outputs.deploy_dir_upload }}
          MY_ZIPFILE: ${{ steps.load_config.outputs.zipfile_upload }}
        run: |
          mkdir ${{ env.MY_DIR }}
          cd ${{ env.MY_DIR }}
          python -m pip install boto3 PyYAML -t .
          cp "../${{ steps.load_config.outputs.path_upload }}" .
          cp ../config.yml .
          zip --quiet -r "../${{ env.MY_ZIPFILE }}" . \
          -x "*.pyc" -x "*__pycache__*" -x "*.dist-info*"
          cd ..
          ls -ltAh | tail -n +2 | head -1
          aws lambda update-function-code \
          --function-name ${{ steps.load_config.outputs.lambda_upload }} \
          --zip-file fileb://${{ env.MY_ZIPFILE }}


  # _ Web _

  # Auxiliary job that checks if any HTML, template, CSS, JS file(s) changed.
  any-web-assets-changed:
    needs: yaml-style-quality
    if: ${{ !failure() && !cancelled() }}
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      any_web_assets_were_updated:
        ${{ steps.detect_web_diff.outputs.any_changed }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - id: detect_web_diff
        uses: ./.github/actions/changed-files
        with:
          files: '**/*.{html,css,js}'
      - run: |
          echo 'Did any web assets change in this commit: '
          echo ${{ steps.detect_web_diff.outputs.any_changed }}

  # Lint HTML, CSS, JS.
  web-style-code-quality:
    needs: any-web-assets-changed
    if: >
      !failure() && !cancelled() &&
      needs.any-web-assets-changed.outputs.any_web_assets_were_updated == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - uses: actions/checkout@v4

      - id: load_config
        run: |
          echo "version=$(yq '.nodejs_version' config.yml)" >> $GITHUB_OUTPUT
          echo "path_css=$(yq '.css_path' config.yml)" >> $GITHUB_OUTPUT

      - uses: actions/setup-node@v4
        with:
          node-version: ${{ steps.load_config.outputs.version }}

      - name: Lint CSS.
        run: |
          npm install --global stylelint stylelint-config-standard
          npx stylelint ${{ steps.load_config.outputs.path_css }}/*.css

      - name: Lint HTML.
        run: |
          npm install --global html-validate
          html-validate .

      - name: Lint JavaScript.
        run: |
          npm install --global standard
          npx standard

  # Upload web files to RVCG.com bucket + invalidate CloudFront distribution.
  deploy-web-assets:
    needs: web-style-code-quality
    if: >-
      !failure() && !cancelled() &&
      needs.web-style-code-quality.result == 'success'
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - uses: actions/checkout@v4

      - id: load_config
        run: |
          echo "folder_web=$(yq '.web_path' config.yml)" >> $GITHUB_OUTPUT
          echo "region=$(yq '.region' config.yml)" >> $GITHUB_OUTPUT
          echo "id=$(yq '.distribution' config.yml)" >> $GITHUB_OUTPUT
          echo "bucket=$(yq '.main_bucket' config.yml)" >> $GITHUB_OUTPUT
          echo "folder_html=$(yq '.html_folder' config.yml)" >> $GITHUB_OUTPUT

      - name: Load AWS credentials from GitHub secrets.
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID_RVCGS }}
          aws-secret-access-key: >
            ${{ secrets.AWS_SECRET_ACCESS_KEY_RVCGS }}
          aws-region: ${{ steps.load_config.outputs.region }}

      - name: Sync web assets to S3.
        env:
          MY_WEB: ${{ steps.load_config.outputs.folder_web }}
        run: |
          aws s3 sync \
          ${{ env.MY_WEB }}/${{ steps.load_config.outputs.folder_html }} \
          s3://${{ steps.load_config.outputs.bucket }} \
          --exclude "*" \
          --include "*.html" \
          --delete
          aws s3 sync \
          ${{ env.MY_WEB }} \
          s3://${{ steps.load_config.outputs.bucket }} \
          --exclude "*" \
          --include "*.css" \
          --include "*.js" \
          --delete

      - name: Invalidate CloudFront cache.
        run: >
          aws cloudfront create-invalidation
          --distribution-id ${{ steps.load_config.outputs.id }}
          --paths '/*'

      - name: Verify critical index HTML is in web-assets bucket.
        run: |
          aws s3 ls s3://${{ steps.load_config.outputs.bucket }}/index.html
          if [ $? -ne 0 ]
          then
            echo 'Failing workflow as index page is missing! '
            exit 3
          fi
