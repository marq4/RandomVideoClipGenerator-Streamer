---
# DO NOT even think about multiple workflows for CICD!

name: CICD

on: push

env:
  # _ Python _
  # Specify minimum code coverage for Unit Testing:
  TARGET_COVERAGE: 40
  CORE_SUBFOLDER: 'PythonCore'
  SCRIPT_NAME_CORE: 'random_video_clip_generator.py'
  # Single place to update Python version for this workflow:
  PYTHON_VERSION: '3.10'
  # _ Cloud + Web _
  REGION: 'us-east-2'
  CLOUD_SUBFOLDER: 'CloudService'
  CSS_STYLESHEET: 'styles.css'
  # Terraform:
  TF_MIN_VERSION: '1.13'


jobs:

  # _ Meta-code _

  # Auxiliary job that checks if any YAML file(s) changed.
  any-yaml-changed:
    runs-on: ubuntu-latest
    timeout-minutes: 3
    outputs:
      any_yaml_files_were_updated:
        ${{ steps.detect_yaml_diff.outputs.any_changed }}
    steps:
      # Fetch all history for version tagging:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - id: detect_yaml_diff
        uses: ./.github/actions/changed-files
        with:
          files: "**/*.{yml,yaml}"
      - run: |
          echo 'Did any YAML file(s) change in this commit: '
          echo ${{ steps.detect_yaml_diff.outputs.any_changed }}

  # Auxiliary job that checks if any Terraform file(s) changed.
  any-tf-changed:
    runs-on: ubuntu-latest
    timeout-minutes: 3
    outputs:
      any_tf_files_were_updated:
        ${{ steps.detect_tf_diff.outputs.any_changed }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - id: detect_tf_diff
        uses: ./.github/actions/changed-files
        with:
          files: "**/*.tf"
      - run: |
          echo 'Did any Terraform file(s) change in this commit: '
          echo ${{ steps.detect_tf_diff.outputs.any_changed }}

  # Lint YAML.
  yaml-style-quality:
    needs: any-yaml-changed
    if: needs.any-yaml-changed.outputs.any_yaml_files_were_updated == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - uses: actions/checkout@v4

      - name: Lint YAML files.
        uses: frenck/action-yamllint@v1

  # Format + Validate + Lint Terraform:
  tf-style-quality:
    needs: any-tf-changed
    if: needs.any-tf-changed.outputs.any_tf_files_were_updated == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 11
    defaults:
      run:
        working-directory: ./Terraform
    env:
      TFLINT_URL: >-
        'https://raw.githubusercontent.com/terraform-linters/tflint/master/install_linux.sh'

    steps:
      - uses: actions/checkout@v4

      - name: Verify no state files committed.
        run: |
          if find . -name "*.tfstate*" -o -name "*.tfvars" \
          | grep -q .
          then
            echo '!!! Caution !!! '
            echo 'Found potentially sensitive Terraform state file in commit. '
            echo 'Aborting. '
            exit 1
          fi

      - uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_MIN_VERSION }}

      - name: Install TFlint.
        run: curl -s  ${{ env.TFLINT_URL }} | bash

      - run: terraform fmt -check -recursive
        continue-on-error: false

      - run: terraform init -backend=false
        env:
          AWS_REGION: ${{ env.REGION }}

      - run: terraform validate

      - run: tflint --init && tflint


  # _ Python _

  # Auxiliary job that checks if any Python file(s) changed.
  any-python-changed:
    needs: yaml-style-quality
    # Run even if upstream was skipped, but not if it failed:
    if: ${{ !failure() && !cancelled() }}
    runs-on: ubuntu-latest
    timeout-minutes: 3
    outputs:
      any_python_files_were_updated:
        ${{ steps.detect_python_diff.outputs.any_changed }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - id: detect_python_diff
        uses: ./.github/actions/changed-files
        with:
          files: '**/*.py'
      - run: |
          echo 'Did any Python file(s) change in this commit: '
          echo ${{ steps.detect_python_diff.outputs.any_changed }}

  # Python lint, type-checking, import order.
  # Dependency audit.
  # Only runs if any Python files changed.
  python-code-quality:
    needs: any-python-changed
    # Run even if ANY upstream was skipped (like yaml-lint),
    #   but not if it failed:
    if: >
      !failure() && !cancelled() &&
      needs.any-python-changed.outputs.any_python_files_were_updated == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 9
    env:
      PYTHONPATH: .

    steps:
      - uses: actions/checkout@v4

      - uses: ./.github/actions/set-up-python
        with:
          project-version: ${{ env.PYTHON_VERSION }}

      - uses: ./.github/actions/install-dependencies

      - name: Lint Python code.
        run: pylint .

      - name: Type checking.
        run: mypy .

      - name: Import ordering.
        run: isort --check .

      - name: Dependency security audit.
        run: pyscan

  # Runs on Windows: unit + code coverage, integration.
  # Only for a potential release and if code quality cleared.
  # TMP: SKIPPING tests!!!
  python-code-testing:
    needs: python-code-quality
    # Without the first conditions
    #   this job gets skipped IF yaml-lint job gets skipped,
    #   as it depends on it indirectly up the chain,
    #   (so no Python code tests if YAML doesn't change).
    # Only test Python code if commit will trigger a Release:
    if: >-
      !failure() && !cancelled() &&
      (contains(github.event.head_commit.message, 'feat!:') ||
      contains(github.event.head_commit.message, 'feat:') ||
      contains(github.event.head_commit.message, 'fix:'))
    runs-on: windows-latest
    timeout-minutes: 13
    env:
      PYTHONPATH: .
      SKIP_TESTS: true

    steps:
      - uses: actions/checkout@v4
        if: env.SKIP_TESTS != 'true'

      - name: Install FFMpeg, VLC.
        if: env.SKIP_TESTS != 'true'
        # To verify VLC installation:
        # & "C:\Program Files\VideoLAN\VLC\vlc-cache-gen.exe" --version
        run: |
          choco install ffmpeg -y
          choco install vlc -y

      - uses: ./.github/actions/set-up-python
        if: env.SKIP_TESTS != 'true'
        with:
          project-version: ${{ env.PYTHON_VERSION }}

      - uses: ./.github/actions/install-dependencies
        if: env.SKIP_TESTS != 'true'

      - name: Setup (create fake example videos).
        if: env.SKIP_TESTS != 'true'
        run: python tests/setup.py

      - name: Unit testing.
        if: env.SKIP_TESTS != 'true'
        run: pytest -vvv tests/unit_tests.py

      - name: Code coverage.
        if: env.SKIP_TESTS != 'true'
        run: >
          pytest --cov=${{ env.CORE_SUBFOLDER }}
          --cov-fail-under=${{ env.TARGET_COVERAGE }}
          tests/unit_tests.py

      - name: Integration testing.
        if: env.SKIP_TESTS != 'true'
        run: pytest -vvv tests/integration_tests.py

  # Auxiliary job that checks if core Python script changed specifically.
  core-changed:
    needs: yaml-style-quality
    if: ${{ !failure() && !cancelled() }}
    runs-on: ubuntu-latest
    timeout-minutes: 3
    outputs:
      core_python_script_was_updated:
        ${{ steps.detect_core_python_script_diff.outputs.any_changed }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - id: detect_core_python_script_diff
        uses: ./.github/actions/changed-files
        with:
          files: ${{ env.CORE_SUBFOLDER }}/${{ env.SCRIPT_NAME_CORE }}
      - run: |
          echo 'Did the core Python script change in this commit: '
          echo ${{ steps.detect_core_python_script_diff.outputs.any_changed }}

  # Conventional Commits Release (PSR: Python Semantic Release).
  # Only runs if core Python script changed + special commit message.
  release:
    needs: [python-code-testing, core-changed]
    if: >-
      !failure() && !cancelled() &&
      needs.python-code-testing.result == 'success' &&
      needs.core-changed.outputs.core_python_script_was_updated == 'true' &&
      (contains(github.event.head_commit.message, 'feat!:') ||
      contains(github.event.head_commit.message, 'feat:') ||
      contains(github.event.head_commit.message, 'fix:'))
    runs-on: ubuntu-latest
    timeout-minutes: 9
    env:
      PYTHONPATH: .
    # Allow commits, tags, pushes:
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4

      - uses: ./.github/actions/set-up-python
        with:
          project-version: ${{ env.PYTHON_VERSION }}

      - run: python -m pip install python-semantic-release

      - name: Configure Git.
        run: |
          git config user.name 'github-actions[bot]'
          git config user.email 'github-actions[bot]@users.noreply.github.com'

      # Bump version, commit, tag, publish GitHub Release:
      - name: Semantic Release.
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        # Locally do: python -m semantic_release
        run: |
          # semantic-release --verbose --strict --noop --version
          semantic-release --verbose --strict --config pyproject.toml \
            version --skip-build --vcs-release

  deploy-to-s3-and-lambda:
    needs: [release, core-changed]
    if: >-
      !failure() && !cancelled() &&
      needs.release.result == 'success' &&
      needs.core-changed.outputs.core_python_script_was_updated == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 16
    env:
      PYTHONPATH: .
      VERIFY_BASH_SCRIPT: '.github/scripts/verify_deployed_version.sh'
      SCRIPT_NAME_LIST: 'send_suggested_yt_video_list.py'
      SCRIPT_NAME_CLEANUP: 's3_cleanup.py'
      SCRIPT_NAME_UPLOAD: 'presigned_url_generator.py'

    steps:
      - name: Checkout code (deep, main).
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: main

      - name: Pull release.
        run: git pull origin main

      - uses: ./.github/actions/set-up-python
        with:
          project-version: ${{ env.PYTHON_VERSION }}

      # No need to install AWS CLI.
      # These are needed or import breaks.
      # (Script is executed to verify version).
      - run: python -m pip install boto3 boto3-stubs boto3-stubs[s3] PyYAML

      - name: Load AWS credentials from GitHub secrets.
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID_RVCGS }}
          aws-secret-access-key: >
            ${{ secrets.AWS_SECRET_ACCESS_KEY_RVCGS }}
          aws-region: ${{ env.REGION }}

      - id: load_config
        run: |
          SCRIPTS_BUCKET_NAME=$(yq '.scripts_bucket_name' config.yml)
          echo "bucket_scripts=$SCRIPTS_BUCKET_NAME" >> $GITHUB_OUTPUT
          CORE_FUNCTION_NAME=$(yq '.core_function_name' config.yml)
          echo "lambda_core=$CORE_FUNCTION_NAME" >> $GITHUB_OUTPUT
          LIST_FUNCTION_NAME=$(yq '.list_function_name' config.yml)
          echo "lambda_list=$LIST_FUNCTION_NAME" >> $GITHUB_OUTPUT
          CLEANUP_FUNCTION_NAME=$(yq '.cleanup_function_name' config.yml)
          echo "lambda_cleanup=$CLEANUP_FUNCTION_NAME" >> $GITHUB_OUTPUT
          UPLOAD_FUNCTION_NAME=$(yq '.upload_function_name' config.yml)
          echo "lambda_upload=$UPLOAD_FUNCTION_NAME" >> $GITHUB_OUTPUT

      - name: Upload script to S3.
        env:
          BUCKET_FOR_SCRIPT: ${{ steps.load_config.outputs.bucket_scripts }}
        run: >
          file=${{ env.SCRIPT_NAME_CORE }}
          aws s3 cp ${{ env.CORE_SUBFOLDER }}/${{ env.SCRIPT_NAME_CORE }}
          s3://${{ env.BUCKET_FOR_SCRIPT }}/${{ env.SCRIPT_NAME_CORE }}
          --content-type 'text/x-python'
          --content-disposition "attachment; filename=$file"
          --metadata-directive REPLACE

      - name: Verify correct version is live (for script users).
        env:
          BUCKET_FOR_SCRIPT: ${{ steps.load_config.outputs.bucket_scripts }}
        run: |
          chmod +x ${{ env.VERIFY_BASH_SCRIPT }}
          ${{ env.VERIFY_BASH_SCRIPT }} \
            "${{ env.CORE_SUBFOLDER }}" \
            "${{ env.SCRIPT_NAME_CORE }}" \
            "${{ env.BUCKET_FOR_SCRIPT }}"

      - name: Deploy core to Lambda (website / Cloud service users).
        env:
          CORE_FUNCTION: ${{ steps.load_config.outputs.lambda_core }}
        run: |
          script="${{ env.CORE_SUBFOLDER }}/${{ env.SCRIPT_NAME_CORE }}"
          mkdir main-lambda-package
          cd main-lambda-package
          python -m pip install boto3 mypy-boto3-s3 -t .
          cp ../$script .
          zipfile=corefunctionality.zip
          zip --quiet -r ../$zipfile . \
          -x "*.pyc" -x "*__pycache__*" -x "*.dist-info*"
          cd ..
          ls -ltAh | tail -n +2 | head -1
          aws lambda update-function-code \
          --function-name ${{ env.CORE_FUNCTION }} \
          --zip-file fileb://$zipfile

      - name: Deploy YT video list code to Lambda.
        env:
          LIST_FUNCTION: ${{ steps.load_config.outputs.lambda_list }}
        run: |
          script="${{ env.CLOUD_SUBFOLDER }}/${{ env.SCRIPT_NAME_LIST }}"
          zipfile=listmdfunctionality.zip
          zip --quiet --junk-paths $zipfile $script List.md
          ls -ltAh | tail -n +2 | head -1
          aws lambda update-function-code \
          --function-name ${{ env.LIST_FUNCTION }} \
          --zip-file fileb://$zipfile

      - name: Deploy S3 cleanup code to Lambda.
        env:
          CLEANUP_FUNCTION: ${{ steps.load_config.outputs.lambda_cleanup }}
        run: |
          script="${{ env.CLOUD_SUBFOLDER }}/${{ env.SCRIPT_NAME_CLEANUP }}"
          zipfile=s3cleanupfunctionality.zip
          mkdir cleanup-lambda-package
          cd cleanup-lambda-package
          python -m pip install boto3 -t .
          cp ../$script .
          zip --quiet -r ../$zipfile . \
          -x "*.pyc" -x "*__pycache__*" -x "*.dist-info*"
          cd ..
          ls -ltAh | tail -n +2 | head -1
          aws lambda update-function-code \
          --function-name ${{ env.CLEANUP_FUNCTION }} \
          --zip-file fileb://$zipfile

      - name: Deploy upload code.
        env:
          UPLOAD_FUNCTION: ${{ steps.load_config.outputs.lambda_upload }}
        run: |
          script="${{ env.CLOUD_SUBFOLDER }}/${{ env.SCRIPT_NAME_UPLOAD }}"
          zipfile=uploadfunctionality.zip
          mkdir upload-lambda-package
          cd upload-lambda-package
          python -m pip install boto3 -t .
          cp ../$script .
          zip --quiet -r ../$zipfile . \
          -x "*.pyc" -x "*__pycache__*" -x "*.dist-info*"
          cd ..
          ls -ltAh | tail -n +2 | head -1
          aws lambda update-function-code \
          --function-name ${{ env.UPLOAD_FUNCTION }} \
          --zip-file fileb://$zipfile


  # _ Web _

  # Auxiliary job that checks if the CSS stylesheet changed specifically.
  css-changed:
    needs: yaml-style-quality
    if: ${{ !failure() && !cancelled() }}
    runs-on: ubuntu-latest
    timeout-minutes: 2
    outputs:
      css_stylesheet_was_updated:
        ${{ steps.detect_css_stylesheet_diff.outputs.any_changed }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - id: detect_css_stylesheet_diff
        uses: ./.github/actions/changed-files
        with:
          files: ${{ env.CLOUD_SUBFOLDER }}/${{ env.CSS_STYLESHEET }}
      - run: |
          echo 'Did the CSS stylesheet change in this commit: '
          echo ${{ steps.detect_css_stylesheet_diff.outputs.any_changed }}

  # Auxiliary job that checks if any HTML document(s) changed.
  any-html-changed:
    needs: yaml-style-quality
    if: ${{ !failure() && !cancelled() }}
    runs-on: ubuntu-latest
    timeout-minutes: 3
    outputs:
      any_html_documents_were_updated:
        ${{ steps.detect_html_diff.outputs.any_changed }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - id: detect_html_diff
        uses: ./.github/actions/changed-files
        with:
          files: '**/*.{html,html.template}'
      - run: |
          echo 'Did any HTML document(s) change in this commit: '
          echo ${{ steps.detect_html_diff.outputs.any_changed }}

  # Auxiliary job that checks if any JavaScript file(s) changed.
  any-js-changed:
    needs: yaml-style-quality
    if: ${{ !failure() && !cancelled() }}
    runs-on: ubuntu-latest
    timeout-minutes: 3
    outputs:
      any_js_files_were_updated:
        ${{ steps.detect_js_diff.outputs.any_changed }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - id: detect_js_diff
        uses: ./.github/actions/changed-files
        with:
          files: '**/*.js'
      - run: |
          echo 'Did any JavaScript file(s) change in this commit: '
          echo ${{ steps.detect_js_diff.outputs.any_changed }}

  # Lint CSS.
  css-style-quality:
    needs: css-changed
    if: >
      !failure() && !cancelled() &&
      needs.css-changed.outputs.css_stylesheet_was_updated == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 4

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Lint CSS.
        run: |
          npm install --global stylelint stylelint-config-standard
          npx stylelint ${{ env.CLOUD_SUBFOLDER }}/${{ env.CSS_STYLESHEET }}

  # Lint HTML.
  html-style-quality:
    needs: any-html-changed
    if: >
      !failure() && !cancelled() &&
      needs.any-html-changed.outputs.any_html_documents_were_updated == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@v4

      - name: Generate HTML from template.
        run: |
          cd ${{ env.CLOUD_SUBFOLDER }}
          envsubst < index.html.template > index.html
          ls -ltAh | tail -n +2 | head -1

      - uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Lint HTML.
        run: |
          npm install --global html-validate
          html-validate .

      - name: Share the generated index HTML with deploy job via Artifacts.
        uses: actions/upload-artifact@v4
        with:
          name: generated-html
          path: ${{ env.CLOUD_SUBFOLDER }}/index.html
          retention-days: 1

  # Only lint JS for now. I MAY add automated testing later.
  # Only runs if any JS files changed.
  js-code-quality:
    needs: any-js-changed
    if: >
      !failure() && !cancelled() &&
      needs.any-js-changed.outputs.any_js_files_were_updated == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 7

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Lint JavaScript.
        run: |
          npm install --global standard
          npx standard

  # Upload web files to RVCG.com bucket + invalidate CloudFront distribution.
  deploy-web-assets:
    needs:
      - css-changed
      - any-html-changed
      - any-js-changed
      - css-style-quality
      - html-style-quality
      - js-code-quality
    if: >-
      !failure() && !cancelled() &&
      (needs.css-style-quality.result == 'success' ||
      needs.html-style-quality.result == 'success' ||
      needs.js-code-quality.result == 'success')
    runs-on: ubuntu-latest
    timeout-minutes: 20
    env:
      BUCKET_WEB: 'randomvideoclipgenerator.com'
      CLOUDFRONT_DISTRIBUTION: 'EWDPJFG1ZNBMV'

    steps:
      - uses: actions/checkout@v4

      - name: Retrieve index HTML generated in Lint-HTML job.
        uses: actions/download-artifact@v4
        with:
          name: generated-html
          path: ${{ env.CLOUD_SUBFOLDER }}

      - name: Load AWS credentials from GitHub secrets.
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID_RVCGS }}
          aws-secret-access-key: >
            ${{ secrets.AWS_SECRET_ACCESS_KEY_RVCGS }}
          aws-region: ${{ env.REGION }}

      - name: Sync web assets to S3.
        run: >
          ls -ltAh | tail -n +2 | head -1
          aws s3 sync
          ${{ env.CLOUD_SUBFOLDER }}
          s3://${{ env.BUCKET_WEB }}
          --exclude "*.template"
          --delete

      - name: Invalidate CloudFront cache.
        run: >
          aws cloudfront create-invalidation
          --distribution-id ${{ env.CLOUDFRONT_DISTRIBUTION }}
          --paths '/*'
